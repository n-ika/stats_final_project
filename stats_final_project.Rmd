---
title: "Statistics — Final Project"
author: "Nika Jurov"
date: "12/22/2018"
output: html_document
---

```{r include=FALSE}
library(magrittr)
library(dplyr)
source("functions_final_project.R")
```

```{r include=FALSE}
geom_data <- readr::read_csv("geomphon_pilot_results_for_analysis.csv")
```

The data used in this final project is the results data from the Geomphon pilot experiment. It has the same structure as the `STRUT vowel` experiment I want to analyse, except for some minor differences. These differences are: the ABX test was done with a different type of stimuli - they were meant to test consonant and vowel discrimination, while the `STRUT data` only tests the vowel discrimination. Since this is an exercice for analyzing the real data later on, I will not make any difference between C and V analysis. In addition, I will analyze only one type of distance difference (the subtraction), even though other types of distances could reveal a different result.

Since this pilot data has no computational model ABX results, I am not including this part, but I am including, at the end, an analysis proposition.

In the table, the important columns for this project are: 

* the column indicating the correct/incorrect participant response `user_corr`,
* the column with distances subtraction `delta_dist_sub`, 
* the columns with phones: `phone_TGT`, `phone_OTH`, `phone_X` [this theoretically corresponds to French and English vowel I want to compare in the `STRUT data` experiment].

**There are XXXX parts of the analysis:**

* 1) I show which phoneme couple (`TGT` vs. `OTH`) has the lowest discrimination rate for each participant subgroup (I filter them by `language`).
* 2) I check what the distances differences predict.
* 3) I compare the human responses to the acoustic distances.
* 4) I do the order statistics to check which couple of sounds has the lowest discrimination rate with bootstrapping.

## 1) LOWEST DISCRIMINATION PER LANGUAGE GROUP

```{r include=FALSE}
fr_summary <- lang_filter(geom_data, "French")
eng_summary <- lang_filter(geom_data, "English")
```



```{r include=FALSE}
fr_combo <- fr_summary %>%
      dplyr::mutate(
        combo1 = 
          paste(phone_TGT, phone_OTH, sep="-"),
        combo2 =
          paste(phone_OTH, phone_TGT, sep="-")) %>%
      dplyr::group_by(combo1, combo2) %>%
      dplyr::summarise(correct_resp = mean(correct_resp)) %>%
      dplyr::ungroup()


fr_triangle <- make_triangle(fr_combo)

fr_triangle  <- fr_triangle %>%
          dplyr::group_by(combo1) %>%
          dplyr::summarise(correct_resp = mean(correct_resp)) %>%
          dplyr::ungroup() %>%
          tidyr::separate(combo1, c("phone_TGT", "phone_OTH"), sep = "-")
          

test_plot <- plot_corr_resp(fr_triangle,
                              "French speakers — discrimination rate 
                                - upper triangle",
                              0.72)
```


```{r include=FALSE}

fr_spk_plot <- plot_corr_resp(fr_summary,
                              "French speakers — discrimination rate",
                              0.72)
eng_spk_plot <- plot_corr_resp(eng_summary,
                              "English speakers — discrimination rate",
                              0.72)
```


English speakers have most problems with [θ] - [f] contrast, then with [ʊ] - [u] and [ʊ] - [ʌ]. This seems correct, as these sounds are also phonologically quite close.


```{r echo=FALSE}
eng_spk_plot
```

French speakers have most problems with [θ] - [f] contrast. Interestingly, they also show bad discrimination for [θ] - [s] (unlike the English speakers) and a worse discrimination of [æ] - [ɑ] than the English speakers. This might be the native language effect.

```{r echo=FALSE}
fr_spk_plot
test_plot
```






## 2) LOWEST DISCRIMINATION PREDICTED BY ACOUSTIC DISTANCES
```{r include=FALSE}
corr_resp_mfcc <- geom_data %>%
  dplyr::group_by(tripletid, distance_OTH, distance_TGT) %>%
  dplyr::mutate(
    correct_resp = ifelse(
      (distance_OTH - distance_TGT) > 0, 1, 0))

mfcc_perc_error <- corr_resp_mfcc %>%
  dplyr::group_by(phone_TGT, phone_OTH) %>%
  dplyr::summarise(correct_resp = mean(correct_resp)) %>%
  dplyr::ungroup()


dist_prediction_plot <- plot_corr_resp(
                            mfcc_perc_error,
                            "Distances — discrimination rate prediction",
                            0.5)
```

```{r echo=FALSE}
dist_prediction_plot
```


## 3) HUMAN RESPONSES VS. ACOUSTIC DISTANCES


```{r echo = FALSE}
human_mfcc_summary <- corr_resp_mfcc %>%
  dplyr::group_by(phone_TGT, phone_OTH) %>%
  dplyr::summarise(human_resp = mean(user_corr),
                   mfcc_resp = mean(correct_resp)) %>%
  dplyr::ungroup()


ggplot2::ggplot(human_mfcc_summary, 
                ggplot2::aes(x=mfcc_resp,
                             y=human_resp)) +
                ggplot2::geom_text(
                  ggplot2::aes(label=paste(phone_TGT, 
                                           phone_OTH, 
                                           sep="-")),
                  check_overlap = TRUE) +
                ggplot2::labs(title = "Distances predictions vs. human responses",
                              x = "Predictions by distances",
                              y = "Human discrimination")

```

From the plot above we see that this relation is not linear. Ideally one would think that the further away the distances, the better the discrimination rate (because less sound similarity would mean a better sound distinction). 
I take the *acoustic distances* as the **predictor** and the *human responses* as the **dependent variable**.

If we keep the distances as they are without using the means, we see that they will be grouped either at 0 or at 1. This is not a good fit for a linear model, but for a logistic one.

I changed the distances into predicted responses: if the subtraction of the distance `phone_OTH and phone_X` minus the distance `phone_TGT and phone_X` is not bigger than 0, the predicted response is 0, otherwise 1. This means that the mean responses predicted by distances should correspond to some number between 0 and 1. However, since there is only a few examples per each pair, there are three visible means the distances predict: 0, 0.25, 0.5 or 1. This does not really help with knowing whether the acoustic distances have or do not have any influence on human responses.

In order to verify this, we first need to inspect the plot and the means of the correct responses predicted by the distances and as replied by humans. 

```{r echo=FALSE}

corr_resp_mfcc_FR <- corr_resp_mfcc %>%
                          dplyr::filter(subject_language.x ==
                                          "French")

corr_resp_mfcc_EN <- corr_resp_mfcc %>%
                          dplyr::filter(subject_language.x ==
                                          "English")

mfcc_mean <- mean(corr_resp_mfcc$correct_resp)
human_mean_all <- mean(corr_resp_mfcc$user_corr)
human_mean_FR <- mean(corr_resp_mfcc_FR$user_corr)
human_mean_EN <- mean(corr_resp_mfcc_EN$user_corr)

summary_means <- dplyr::data_frame("Mean distances response" =
                                     mfcc_mean,
                                   "Mean human response - all" =
                                     human_mean_all,
                                   "Mean human response - French" =
                                     human_mean_FR,
                                   "Mean human response - English" =
                                     human_mean_EN)
knitr::kable(summary_means)
```


The means are nearly identical (*distances mean*: `0.7571602`, *humans mean*: `0.7674015`). However, there is a big difference in their *"criteria"* that give these results. Humans will rely on many critera, like the acoustic proximity, the top-down interference, the duration, the voice (pitch, color etc.) similarity, their native language and so on. Even though the lexical knowledge should not play any role since these were non words, one never knows what a CVC syllable could evoke in someone's head when hearing it. 

On the other hand, the acoustic distances differences come from MFCC vectors, which predict the correct response according to the subtraction result. Their criteria is the acoustic proximity between the `d(TGT-X)` and `d(OTH-X)`, where we would want `d(OTH-X) > d(TGT-X)`. This acoustic proximity is the actual occurrence of two particular sounds. First, this cannot be equated completely with human perception. Second, the results show that even though the mean is very similar, the pairs which were discriminated correctly are often not the same as those predicted by the distances. I think this is because of *how* the pair is judged (the criteria used), even though the means seem to show similar results.

```{r echo=FALSE}
human_mfcc_summary_FR <- corr_resp_mfcc_FR %>%
  dplyr::group_by(phone_TGT, phone_OTH) %>%
  dplyr::summarise(human_resp = mean(user_corr),
                   mfcc_resp = mean(correct_resp)) %>%
  dplyr::ungroup()

human_mfcc_summary_EN <- corr_resp_mfcc_EN %>%
  dplyr::group_by(phone_TGT, phone_OTH) %>%
  dplyr::summarise(human_resp = mean(user_corr),
                   mfcc_resp = mean(correct_resp)) %>%
  dplyr::ungroup()

cor_all <- cor.test(human_mfcc_summary$mfcc_resp,
                    human_mfcc_summary$human_resp)[4]
cor_FR <- cor.test(human_mfcc_summary_FR$mfcc_resp,
                    human_mfcc_summary_FR$human_resp)[4]
cor_EN <- cor.test(human_mfcc_summary_EN$mfcc_resp,
                    human_mfcc_summary_EN$human_resp)[4]

correlation_summary <- dplyr::data_frame("Correlation - all" =
                                           cor_all,
                                         "Correlation - French" =
                                           cor_FR,
                                         "Correlation - English" =
                                           cor_EN)

knitr::kable(correlation_summary, 
             caption = "Correlation between MFCCs and human responses")

```


Correlation coefficient `R=0.44` shows that indeed there is some correlation, but not much. Let's now do the logistic regression to check whether the acoustic distances have or do not have any real influence (i.e. are they significantlly influencing the human discrimination). The null hypothesis is that they have no effect on results, while the alternative is that they do have an effect. With `glm()` model using the method `family=binomial` we get `p=4.282809e-08`. This means that indeed, there is the acoustic distance effect and we can reject the H0.


```{r echo = FALSE}
logit_m <- glm(user_corr ~ correct_resp, 
               data = corr_resp_mfcc, 
               family=binomial(link='logit'))

p_logit_m <- coef(summary(logit_m))[2,4]

logit_m_FR <- glm(user_corr ~ correct_resp, 
               data = corr_resp_mfcc_FR, 
               family=binomial(link='logit'))

p_logit_m_FR <- coef(summary(logit_m_FR))[2,4]

logit_m_EN <- glm(user_corr ~ correct_resp, 
               data = corr_resp_mfcc_EN, 
               family=binomial(link='logit'))

p_logit_m_EN <- coef(summary(logit_m_EN))[2,4]

pval_logit_summary <- dplyr::data_frame("P-Value: all" =
                                           p_logit_m,
                                         "P-Value: French" =
                                           p_logit_m_FR,
                                         "P-Value: English" =
                                           p_logit_m_EN)

knitr::kable(pval_logit_summary, 
             caption = "P-values of logistic models")
```

To check the power of this statistical analysis, I decided to permute the acoustic distances predictions with replacement. In this way, I generate many samples and do the logistic regression test on each of them. The successful sample has a p value smaller than 0.05 and this is how the power is predicted: by dividing the number of successful samples by the number of all tests. We get the power of 1 which makes sense - because we would need very few correct responses `1` to get a p value that is bigger than 0.05. I also checked this with p value being smaller than 0.0001.


```{r echo = FALSE}

alpha05 <- statistical_power(corr_resp_mfcc, 0.05)
alpha001 <- statistical_power(corr_resp_mfcc, 0.0001)

summary_power <- dplyr::bind_rows(alpha05,
                                  alpha001)

knitr::kable(summary_power)
```

```{r include = FALSE}
means_permuted <- rep(0, 9999)
n_successes <- rep(0, 9999)
alpha <- 0.05
for (i in 1:9999) {
          permuted_geom <- dplyr::data_frame(
                                   permuted_english = sample(
                                   c(0,1), 
                                   (dim(corr_resp_mfcc)[1]/2),
                                   replace = TRUE),
                                   permuted_french = sample(
                                   c(0,1),
                                   (dim(corr_resp_mfcc)[1]/2),
                                   replace = TRUE))
  
          mean_diff <- mean(permuted_geom$permuted_english) - 
                        mean(permuted_geom$permuted_french)
          means_permuted[i] <- mean_diff
      
       
}

means_permuted_df <- dplyr::data_frame(means_permuted=means_permuted)
```

```{r echo=FALSE}
obs_mean_diff <- mean(corr_resp_mfcc_EN$user_corr) -
                 mean(corr_resp_mfcc_FR$user_corr)
means_permuted_plot <- ggplot2::ggplot(means_permuted_df,
                       ggplot2::aes(x = means_permuted)) +
                       ggplot2::geom_histogram(bins = 100, alpha=0.5) +
                       ggplot2::geom_vline(xintercept = obs_mean_diff) +
                       ggplot2::labs(title ="Differences of the permuted means", 
                       x = "Mean of responses by English minus mean of responses by French listeners",
                       y = "Count")
means_permuted_plot
```


I checked if there is a significant difference between the responses of the two different native language groups.

When checking the mean difference with permutation, the observed mean difference is removed from the center of the distribution of the permuted mean differences. The two groups were simulated by having the 0.5 probability of having responses 0 or 1. The number of the observed mean difference is quite small and close to zero (`-0.056`). However, when permuting the values we see that the observed mean difference lies outside the distribution of the permuted mean differences which are centered at 0.


This and the previous results show that we can reject the H0 which states that the acoustic predictions have no influence on human responses. We also see that the observed mean difference between the two groups separated by native language is not exactly 0. Globally, we can conclude that acoustic distances have influence on perception and that there is some significant difference between the two language groups.

But to me it is interesting to know which pair specifically was influenced by the distance more than another and was problematic for a language group.


## 4) ORDER STATISTICS

To understand if the problematic (meaning, more difficult to discriminate) phone pairs (e.g., [θ] - [f]) are similar for each language group, I decided to do the order statistics. 

I compare:

1) order of English vs. order of French listeners (participants);
2) order of all participants vs. order of French participants;
3) order of all participants vs. order of English participants.

I first order the data frames according to the mean of the correct response: from the smallest to the highest value. In this way, I obtain the order of the phone pairs which I then fit into a linear model. By using the `Boot` package, I verify the model with bootstrapping - simulating the sampling distribution of the coefficient. We can see the bootstrapped coefficient in the histograms below; the H0 here is that coefficient is 0 and has no influence on the data. 

Of course, the orders do not influence one another, but I chose the linear model because they graphically resemble to it.

Comparing the order 1), the plot seems slightly linear, but it is not graphically completely clear. However, orders 2) and 3) seem graphically linear.

```{r echo=FALSE}
plot(order(ordered_EN$combo1), 
     order(ordered_FR$combo1), 
     xlab = "English order",
     ylab = "French order")
plot(order(ordered_EN$combo1), 
     order(ordered_all$combo1),
     xlab = "English order",
     ylab = "All order")
plot(order(ordered_FR$combo1), 
     order(ordered_all$combo1), 
     xlab = "French order",
     ylab = "All order")
```


In addition, the idea is only to compare the orders and see how much they match. Perhaps this is not the best way to do it, but I did not know how else to do it (one option could be - as far as internet says - Wilcoxon test, checking the medians of the orders, but I do not see why one is more appropriate than the other). Wilcoxon test confirms that the orders are significantly different from one another, meaning each language group discriminates better (or worse) different phone pairs.

```{r echo=FALSE}
wilcox.test(order(ordered_EN$combo1), 
            order(ordered_FR$combo1), paired=TRUE)
wilcox.test(order(ordered_EN$combo1), 
            order(ordered_all$combo1), paired=TRUE)
wilcox.test(order(ordered_FR$combo1), 
            order(ordered_all$combo1), paired=TRUE)
```


```{r echo=FALSE}
all_spk <- geom_data %>%
    dplyr::group_by(phone_TGT, phone_OTH) %>%
    dplyr::summarise(correct_resp = mean(user_corr)) %>%
    dplyr::ungroup()

ordered_all <- make_pairs(all_spk)
ordered_FR <- make_pairs(fr_summary)
ordered_EN <- make_pairs(eng_summary)
```



```{r echo=FALSE}
logit_coefficient <- function(m){
  return(coef(m)[2])
}

m_H0_FR_EN <- glm(order(ordered_EN$combo1) ~ order(ordered_FR$combo1))
boot_m_H0_FR_EN <- car::Boot(m_H0_FR_EN, f=logit_coefficient,
                       r=9999, method="case")

m_H0_EN_all <- glm(order(ordered_EN$combo1) ~ order(ordered_all$combo1))
boot_m_H0_EN_all <- car::Boot(m_H0_EN_all, f=logit_coefficient,
                       r=9999, method="case")

m_H0_FR_all <- glm(order(ordered_FR$combo1) ~ order(ordered_all$combo1))
boot_m_H0_FR_all <- car::Boot(m_H0_FR_all, f=logit_coefficient,
                       r=9999, method="case")
```


```{r echo=FALSE}
hist(boot_m_H0_FR_EN, xlab = "Order French-English")
hist(boot_m_H0_EN_all, xlab = "Order English-All")
hist(boot_m_H0_FR_all, xlab = "Order French-All")
```

## 5) CONCLUSION

We can confirm that:
* the acoustic distance has influence on human phone discrimination;
* participants from different language groups discriminate some phone pairs better than other language group (that is, the order of phone pairs is different between groups).

Native language seems to play an important role in discrimination.